#!/usr/bin/env python3
"""
Script di test per verificare che tutto il setup funzioni correttamente
"""

import asyncio
import aiohttp
import time
import sys
import json

async def test_ollama_health():
    """Testa la salute di Ollama"""
    print("ğŸ” Test 1: Verifica salute di Ollama...")
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get('http://localhost:11434/api/tags') as response:
                if response.status == 200:
                    data = await response.json()
                    models = [model['name'] for model in data.get('models', [])]
                    if 'llama3.2:latest' in models:
                        print("âœ… Ollama Ã¨ sano e ha il modello llama3.2!")
                        return True
                    else:
                        print("âš ï¸  Ollama Ã¨ sano ma non ha il modello llama3.2")
                        return False
                else:
                    print(f"âŒ Ollama non risponde: {response.status}")
                    return False
    except Exception as e:
        print(f"âŒ Errore nel test di Ollama: {e}")
        return False

async def test_chat_functionality():
    """Testa la funzionalitÃ  di chat"""
    print("ğŸ” Test 2: Test funzionalitÃ  di chat...")
    
    try:
        async with aiohttp.ClientSession() as session:
            payload = {
                "model": "llama3.2",
                "prompt": "Ciao, rispondi solo con 'OK'",
                "stream": False
            }
            
            async with session.post('http://localhost:11434/api/generate', 
                                  json=payload, 
                                  timeout=aiohttp.ClientTimeout(total=60)) as response:
                if response.status == 200:
                    data = await response.json()
                    if 'response' in data:
                        print("âœ… Chat funziona correttamente!")
                        return True
                    else:
                        print("âŒ Risposta non valida da Ollama")
                        return False
                else:
                    print(f"âŒ Errore nella chat: {response.status}")
                    return False
    except Exception as e:
        print(f"âŒ Errore nel test di chat: {e}")
        return False

async def test_frontend():
    """Testa il frontend"""
    print("ğŸ” Test 3: Verifica frontend...")
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get('http://localhost') as response:
                if response.status == 200:
                    print("âœ… Frontend Ã¨ accessibile!")
                    return True
                else:
                    print(f"âŒ Frontend non risponde: {response.status}")
                    return False
    except Exception as e:
        print(f"âŒ Errore nel test del frontend: {e}")
        return False

async def wait_for_services():
    """Aspetta che i servizi siano pronti"""
    print("â³ Aspetto che i servizi siano pronti...")
    
    max_attempts = 30
    for attempt in range(max_attempts):
        try:
            async with aiohttp.ClientSession() as session:
                # Test Ollama
                async with session.get('http://localhost:11434/api/tags') as response:
                    if response.status == 200:
                        data = await response.json()
                        models = [model['name'] for model in data.get('models', [])]
                        if 'llama3.2:latest' in models:
                            print("âœ… Ollama Ã¨ pronto!")
                            break
                
                # Test Frontend
                async with session.get('http://localhost') as response:
                    if response.status == 200:
                        print("âœ… Frontend Ã¨ pronto!")
                        break
                        
        except Exception:
            pass
        
        print(f"â³ Tentativo {attempt + 1}/{max_attempts}...")
        await asyncio.sleep(10)
    else:
        print("âš ï¸  Timeout nell'attesa dei servizi")

async def main():
    """Funzione principale"""
    print("ğŸš€ Test Setup Completo - MediFlow")
    print("=" * 50)
    
    # Aspetta che i servizi siano pronti
    await wait_for_services()
    
    # Esegui i test
    tests = [
        test_ollama_health(),
        test_chat_functionality(),
        test_frontend()
    ]
    
    results = await asyncio.gather(*tests, return_exceptions=True)
    
    print("\n" + "=" * 50)
    print("ğŸ“Š Risultati Test:")
    
    passed = 0
    total = len(results)
    
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"âŒ Test {i+1}: Errore - {result}")
        elif result:
            print(f"âœ… Test {i+1}: Superato")
            passed += 1
        else:
            print(f"âŒ Test {i+1}: Fallito")
    
    print(f"\nğŸ¯ Risultato finale: {passed}/{total} test superati")
    
    if passed == total:
        print("ğŸ‰ Setup completato con successo!")
        print("\nğŸ“‹ L'applicazione Ã¨ pronta:")
        print("   ğŸŒ Frontend: http://localhost")
        print("   ğŸ¤– Ollama: http://localhost:11434")
        print("   ğŸ“Š Backend: http://localhost:8001")
        print("\nğŸ’¡ Ora puoi usare l'applicazione con modelli locali!")
    else:
        print("âš ï¸  Alcuni test sono falliti. Controlla i log.")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
